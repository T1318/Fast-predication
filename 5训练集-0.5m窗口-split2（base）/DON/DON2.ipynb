{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i:\\\\ML\\\\工况合集\\\\5训练集-0.5m窗口-split2（base）\\\\DON', 'h:\\\\Anaconda\\\\envs\\\\my_torch\\\\python310.zip', 'h:\\\\Anaconda\\\\envs\\\\my_torch\\\\DLLs', 'h:\\\\Anaconda\\\\envs\\\\my_torch\\\\lib', 'h:\\\\Anaconda\\\\envs\\\\my_torch', '', 'h:\\\\Anaconda\\\\envs\\\\my_torch\\\\lib\\\\site-packages', 'h:\\\\Anaconda\\\\envs\\\\my_torch\\\\lib\\\\site-packages\\\\win32', 'h:\\\\Anaconda\\\\envs\\\\my_torch\\\\lib\\\\site-packages\\\\win32\\\\lib', 'h:\\\\Anaconda\\\\envs\\\\my_torch\\\\lib\\\\site-packages\\\\Pythonwin', 'I:/ML/工况合集']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"I:/ML/工况合集\")\n",
    "print(sys.path)\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.PDE_Net import DeepONet_NS, weight_init\n",
    "from utils.DataGenerate_DON import Dataset_DON\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.utilities3 import *\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dx = 0.5\n",
    "n_x = int(8/dx)\n",
    "n_y = int(3/dx)\n",
    "p_x = int(800/n_x+1)\n",
    "p_y = int(300/n_y+1)\n",
    "self_split = 2\n",
    "\n",
    "epochs = 1000\n",
    "step_size = 50\n",
    "\n",
    "batch_size = 300\n",
    "learning_rate = 0.01\n",
    "max_norm = 5\n",
    "\n",
    "path_trained_model = r'trained_model'\n",
    "\n",
    "path_label = r'I:\\ML\\工况合集\\5训练集-0.5m窗口-split2（base）\\train_data\\label'\n",
    "\n",
    "path_label_test = r'I:\\ML\\工况合集\\5训练集-0.5m窗口-split2（base）\\test_data\\label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1500, 204])\n",
      "torch.Size([1500, 2601])\n",
      "torch.Size([2601, 2])\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset_DON(path_label,n_x,n_y,p_x,p_y)\n",
    "train_bc,train_variable,train_coordinate,train_min,train_max = dataset.get_data()\n",
    "print(train_bc.shape)\n",
    "print(train_variable.shape)\n",
    "print(train_coordinate.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepONet_NS([204, 512, 512, 512, 512, 512], [2, 16, 64, 256, 512, 512, 512])\n",
    "model.apply(weight_init)\n",
    "model.to(device)\n",
    "myloss = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=100, verbose=True, min_lr=1e-6)\n",
    "begin_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(path_trained_model)\n",
    "if len(file_list) > 0:\n",
    "\tlast_model = os.listdir(path_trained_model)[-1]\n",
    "# save_path = os.path.join(path, 'model_{}.pth'.format(begin_epoch))\n",
    "load_path = os.path.join(path_trained_model, last_model)\n",
    "begin_epoch = load_model(load_path, optimizer, model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_num = 10000\n",
    "points_list = np.array([[0,0],[4,0],[4,1],[5,1],[5,0],[8,0],[8,3],[0,3]])\n",
    "dataset = Dataset_DON(path_label,n_x,n_y,p_x,p_y)\n",
    "dataset_test = Dataset_DON(path_label_test,n_x,n_y,p_x,p_y)\n",
    "\n",
    "train_bc,train_label,train_coordinate,train_min,train_max = dataset.get_data()\n",
    "train_bc = torch.Tensor(train_bc).to(device)\n",
    "train_coordinate = torch.Tensor(train_coordinate).to(device)\n",
    "train_label = torch.Tensor(train_label).to(device)\n",
    "\n",
    "test_bc,test_label,test_coordinate,test_min,test_max = dataset_test.get_data()\n",
    "test_bc = torch.Tensor(test_bc).to(device)\n",
    "test_coordinate = torch.Tensor(test_coordinate).to(device)\n",
    "test_label = torch.Tensor(test_label).to(device)\n",
    "\n",
    "for epoch in range(begin_epoch, epochs+1):\n",
    "\tmodel.train()\n",
    "\n",
    "\toptimizer.zero_grad()\n",
    "\tpred = model(train_bc, train_coordinate)\t\t\t# [train_size,1089]\n",
    "\n",
    "\tloss_train = myloss(pred, train_variable)\n",
    "\tloss_train.backward()\n",
    "\toptimizer.step()\n",
    "\tprint('epoch:', epoch, 'loss_train:', loss_train.item())\n",
    "\tscheduler.step(loss_train)\n",
    "\n",
    "\tmodel.eval()\n",
    "\tpred_test = model(test_bc, test_coordinate)\t\t\t# [test_size,1089]\n",
    "\n",
    "\tloss_test = myloss(pred_test, test_label)\n",
    "\tprint('epoch:', epoch, 'loss_test:', loss_test.item())\n",
    "\n",
    "\tif epoch % 100 == 0:\n",
    "\t\tsave_path = os.path.join(path_trained_model, 'DON_{}.pth'.format(epoch))\n",
    "\t\tsave_model(save_path, epoch, optimizer, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
