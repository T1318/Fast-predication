{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mh5\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mPDE_Net\u001b[39;00m \u001b[39mimport\u001b[39;00m DeepONet_NS, FNO2d, weight_init\n\u001b[0;32m     14\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mDataGenerate_FNO\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset_FNO, Normalize, InNormalize\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtensorboard\u001b[39;00m \u001b[39mimport\u001b[39;00m SummaryWriter\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'utils'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.PDE_Net import DeepONet_NS, FNO2d, weight_init\n",
    "from utils.DataGenerate_FNO import Dataset_FNO, Normalize, InNormalize\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from utils.utilities3 import *\n",
    "\n",
    "torch.set_default_dtype(torch.float32)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modes = 12\n",
    "width = 100\n",
    "dx = 0.5\n",
    "n_x = int(8/dx)\n",
    "n_y = int(3/dx)\n",
    "p_x = int(800/n_x+1)\n",
    "p_y = int(300/n_y+1)\n",
    "self_split = 2\n",
    "\n",
    "epochs = 1000\n",
    "step_size = 50\n",
    "\n",
    "batch_size = 300\n",
    "learning_rate = 0.001\n",
    "iterations = 2*epochs\n",
    "max_norm = 5\n",
    "\n",
    "n_train = 300\n",
    "n_test = 100\n",
    "\n",
    "path_trained_model = r'FNO/trained_model'\n",
    "\n",
    "path_distance = r'train_data/distance'\n",
    "path_label = r'train_data/label'\n",
    "\n",
    "path_distance_test_name = r'distance_test.npy'\n",
    "path_label_test_name = r'label_test.npy'\n",
    "path_distance_test = r'test_data/distance'\n",
    "path_label_test = r'test_data/label'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_distance = torch.empty(0, p_x, p_y, 3)\n",
    "train_label = torch.empty(0, p_x, p_y, 1)\n",
    "test_distance = torch.empty(0, p_x, p_y, 3)\n",
    "test_label = torch.empty(0, p_x, p_y, 1)\n",
    "\n",
    "file_list = os.listdir(path_distance)\n",
    "for file in file_list:\n",
    "\tif file.endswith('.npy'):\n",
    "\t\t\tdistance = np.load(os.path.join(path_distance, file))\n",
    "\t\t\ttrain_distance = torch.cat((train_distance, torch.Tensor(distance)), 0)\n",
    "\n",
    "file_list = os.listdir(path_label)\n",
    "for file in file_list:\n",
    "\tif file.endswith('.npy'):\n",
    "\t\t\tlabel = np.load(os.path.join(path_label, file))\n",
    "\t\t\ttrain_label = torch.cat((train_label, torch.Tensor(label)), 0)\n",
    "\n",
    "file_list = os.listdir(path_distance_test)\n",
    "for file in file_list:\n",
    "\tif file.endswith('.npy'):\n",
    "\t\t\tdistance = np.load(os.path.join(path_distance_test, file))\n",
    "\t\t\ttest_distance = torch.cat((test_distance, torch.Tensor(distance)), 0)\n",
    "\n",
    "file_list = os.listdir(path_label_test)\n",
    "for file in file_list:\n",
    "\tif file.endswith('.npy'):\n",
    "\t\t\tlabel = np.load(os.path.join(path_label_test, file))\n",
    "\t\t\ttest_label = torch.cat((test_label, torch.Tensor(label)), 0)\n",
    "\n",
    "# test_distance = np.load(os.path.join(path_distance_test, path_distance_test_name))\n",
    "# test_label = np.load(os.path.join(path_label_test, path_label_test_name))\n",
    "\n",
    "train_distance = torch.Tensor(train_distance)\n",
    "train_label = torch.Tensor(train_label)\n",
    "test_distance = torch.Tensor(test_distance)\n",
    "test_label = torch.Tensor(test_label)\n",
    "\n",
    "print(train_distance.shape)\n",
    "print(train_label.shape)\n",
    "print(test_distance.shape)\n",
    "print(test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_normalizer = GaussianNormalizer(train_distance)\n",
    "x_data = x_normalizer.encode(train_distance)\n",
    "y_normalizer = GaussianNormalizer(train_label)\n",
    "y_data = y_normalizer.encode(train_label)\n",
    "\n",
    "x_normalizer_test = GaussianNormalizer(test_distance)\n",
    "x_test = x_normalizer_test.encode(test_distance)\n",
    "y_normalizer_test = GaussianNormalizer(test_label)\n",
    "y_test = y_normalizer_test.encode(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unkown layer: SpectralConv2d()\n",
      "unkown layer: SpectralConv2d()\n",
      "unkown layer: SpectralConv2d()\n",
      "unkown layer: SpectralConv2d()\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: MLP(\n",
      "  (mlp1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (mlp2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: MLP(\n",
      "  (mlp1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (mlp2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: MLP(\n",
      "  (mlp1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (mlp2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: MLP(\n",
      "  (mlp1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (mlp2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "unkown layer: Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "unkown layer: MLP(\n",
      "  (mlp1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (mlp2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n",
      "unkown layer: FNO2d(\n",
      "  (p): Linear(in_features=12, out_features=32, bias=True)\n",
      "  (conv0): SpectralConv2d()\n",
      "  (conv1): SpectralConv2d()\n",
      "  (conv2): SpectralConv2d()\n",
      "  (conv3): SpectralConv2d()\n",
      "  (mlp0): MLP(\n",
      "    (mlp1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (mlp2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (mlp1): MLP(\n",
      "    (mlp1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (mlp2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (mlp2): MLP(\n",
      "    (mlp1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (mlp2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (mlp3): MLP(\n",
      "    (mlp1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (mlp2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      "  (w0): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (w1): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (w2): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (w3): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))\n",
      "  (norm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
      "  (q): MLP(\n",
      "    (mlp1): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (mlp2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = FNO2d(modes,modes,width)\n",
    "model.apply(weight_init)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "myloss = nn.MSELoss()\n",
    "\n",
    "writer = SummaryWriter(r'runs\\transtant_model')\n",
    "begin_epoch = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = os.listdir(path_trained_model)\n",
    "if len(file_list) > 0:\n",
    "\tlast_model = os.listdir(path_trained_model)[-1]\n",
    "# save_path = os.path.join(path, 'model_{}.pth'.format(begin_epoch))\n",
    "load_path = os.path.join(path_trained_model, last_model)\n",
    "begin_epoch = load_model(load_path, optimizer, model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(torch.utils.data.TensorDataset(x_data, y_data), batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)\n",
    "\n",
    "x, y = next(iter(train_loader))\n",
    "print(torch.max(x))\n",
    "print(torch.max(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=0.5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=10, verbose=True, min_lr=1e-6)\n",
    "# epochs = 50000\n",
    "for epoch in range(begin_epoch,epochs+1):\n",
    "\tmodel.train()\n",
    "\ttrain_loss_epoch = 0\n",
    "\ttest_loss_epoch = 0\n",
    "\tfor batch in train_loader:\n",
    "\n",
    "\t\tloss_train = 0\n",
    "\t\tdata_x,data_y = batch\n",
    "\n",
    "\t\tx = data_x.float().to(device)\t\t\t# [length,time_step,51,51,3]\n",
    "\t\ty = data_y.float().to(device)\t\t\t# [length,time_step,51,51,3]\n",
    "\n",
    "\t\tpred = model(x)\t\t\t\t\t\t\t\t\t\t\t\t# x:[length,51,51,3], pred:[length,51,51,3]\n",
    "\t\t\n",
    "\t\tpred = y_normalizer.decode(pred)\n",
    "\t\ty = y_normalizer.decode(y)\n",
    "\t\t\n",
    "\t\tloss_train = myloss(pred.clone(), y.clone())\n",
    "\t\t\t\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\ttrain_loss_epoch = train_loss_epoch + loss_train.item()\n",
    "\t\tloss_train.backward(retain_graph=True)\n",
    "\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "\t\toptimizer.step()\n",
    "\t\t# print('epoch:', epoch, 'loss_train:', loss_train.item())\n",
    "\ttrain_loss_epoch = train_loss_epoch / len(train_loader)\n",
    "\tprint('epoch:', epoch, 'loss_train:', train_loss_epoch)\n",
    "\tscheduler.step(train_loss_epoch)\n",
    "\t\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\tfor batch_test in test_loader:\n",
    "\n",
    "\t\t\tloss_test = 0\n",
    "\t\t\ttest_x,test_y = batch_test\n",
    "\t\t\t\n",
    "\t\t\ttest_x = test_x.float().to(device)\t\t\t# [length,time_step,51,51,3]\n",
    "\t\t\ttest_y = test_y.float().to(device)\t\t\t# [length,time_step,51,51,3]\n",
    "\n",
    "\t\t\tpred_test = model(test_x)\n",
    "\n",
    "\t\t\tpred_test = y_normalizer_test.decode(pred_test)\n",
    "\t\t\ttest_y = y_normalizer_test.decode(test_y)\n",
    "\n",
    "\t\t\tloss_test = myloss(pred_test.clone(), test_y.clone())\n",
    "\n",
    "\t\t\ttest_loss_epoch = test_loss_epoch + loss_test.item()\n",
    "\t\ttest_loss_epoch = test_loss_epoch/len(test_loader)\n",
    "\t\tprint('epoch:', epoch, 'loss_test:', test_loss_epoch)\n",
    "\n",
    "\t\t# print('epoch:', epoch, 'loss_test:', loss_test.item())\n",
    "\t\n",
    "\tif epoch % 1000 == 0:\n",
    "\t\tsave_path = os.path.join(path_trained_model, 'FNO_{}.pth'.format(epoch))\n",
    "\t\tsave_model(save_path, epoch, optimizer, model)\n",
    "\n",
    "\t\twriter.add_scalar('loss_train', loss_train.item(), epoch)\n",
    "\t\twriter.add_scalar('loss_test', loss_test.item(), epoch)\n",
    "\n",
    "\t"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
